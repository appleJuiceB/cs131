{"cells":[{"cell_type":"markdown","id":"154c0c0f","metadata":{},"source":["***STEP 1: Creating Dataset***"]},{"cell_type":"code","execution_count":2,"id":"1c5fe04f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["25/04/23 19:53:06 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","# Start Spark session\n","spark = SparkSession.builder.appName(\"CS131 HW Data Analysis\").getOrCreate()\n","\n","# Define the path to your data in GCS\n","gcs_path = \"gs://dataproc-staging-us-central1-156990865139-iitllk4z/data/2019-01-h1.csv\"\n","\n","df = spark.read.csv(gcs_path, header=True, inferSchema=True)\n","# Select relevant columns: passenger_count (4th), pulocationid (8th), dolocationid (9th), total_amount (17th)\n","df_selected = df.select(df.columns[3], df.columns[7], df.columns[8], df.columns[16])\n","# Show first 10 rows\n","df_selected.show(10)"]},{"cell_type":"markdown","id":"fff5cce6","metadata":{},"source":["***STEP 2: CREATING TRAINING AND TESTING DATASETS***"]},{"cell_type":"code","execution_count":6,"id":"1799ba68","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 5:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            0.0|         1.0|         1.0|        90.0|\n","|            0.0|         1.0|         1.0|      101.39|\n","|            0.0|         4.0|         4.0|         4.3|\n","|            0.0|         4.0|         4.0|         4.8|\n","|            0.0|         4.0|         4.0|        5.75|\n","|            0.0|         4.0|        33.0|       17.75|\n","|            0.0|         4.0|        68.0|        15.8|\n","|            0.0|         4.0|        68.0|       16.55|\n","|            0.0|         4.0|        79.0|         5.3|\n","|            0.0|         4.0|        79.0|         5.8|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["trainDF1, testDF1 = df_selected.randomSplit([0.8, 0.2], seed = 42)\n","trainDF1.show(10)"]},{"cell_type":"markdown","id":"bb494361","metadata":{},"source":["**randomSplit messed up training and testing data for some reason, used another method to split data**"]},{"cell_type":"code","execution_count":3,"id":"cd134b26","metadata":{},"outputs":[],"source":["trainDF = df_selected.sample(withReplacement=False, fraction=0.8, seed=42)\n","testDF = df_selected.subtract(trainDF)"]},{"cell_type":"code","execution_count":4,"id":"60ff7739","metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            2.0|       141.0|       234.0|        13.0|\n","|            2.0|       246.0|       162.0|       19.55|\n","|            1.0|       238.0|       151.0|         8.5|\n","|            1.0|       163.0|        25.0|       42.95|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["trainDF.show(10)"]},{"cell_type":"code","execution_count":7,"id":"d325daa1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 23:=============================>                            (2 + 2) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["Train: 2920930 Test: 136146 Total: 3650999\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["print(\"Train:\", trainDF.count(), \"Test:\", testDF.count(), \"Total:\", df_selected.count())"]},{"cell_type":"markdown","id":"40656343","metadata":{},"source":["***STEP 3: CREATING DECISION TREE***"]},{"cell_type":"code","execution_count":9,"id":"78725966","metadata":{},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import DecisionTreeRegressor\n"]},{"cell_type":"code","execution_count":11,"id":"796122c6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+-----------------+------------+\n","|passenger_count|pulocationid|dolocationid|         features|total_amount|\n","+---------------+------------+------------+-----------------+------------+\n","|            1.0|       151.0|       239.0|[1.0,151.0,239.0]|        9.95|\n","|            1.0|       239.0|       246.0|[1.0,239.0,246.0]|        16.3|\n","|            5.0|       193.0|       193.0|[5.0,193.0,193.0]|        7.55|\n","|            5.0|       193.0|       193.0|[5.0,193.0,193.0]|       55.55|\n","|            5.0|       193.0|       193.0|[5.0,193.0,193.0]|       13.31|\n","|            1.0|       163.0|       229.0|[1.0,163.0,229.0]|        9.05|\n","|            2.0|       141.0|       234.0|[2.0,141.0,234.0]|        13.0|\n","|            2.0|       246.0|       162.0|[2.0,246.0,162.0]|       19.55|\n","|            1.0|       238.0|       151.0|[1.0,238.0,151.0]|         8.5|\n","|            1.0|       163.0|        25.0| [1.0,163.0,25.0]|       42.95|\n","+---------------+------------+------------+-----------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["#Create features into single vector\n","assembler = VectorAssembler(inputCols=['passenger_count', 'pulocationid', 'dolocationid'], outputCol='features')\n","vecTrain = assembler.transform(trainDF)\n","vecTrain.select(\"passenger_count\", \"pulocationid\", \"dolocationid\" , \"features\", \"total_amount\").show(10)\n","\n","# Initialize decision tree regressor\n","dt_regressor = DecisionTreeRegressor(featuresCol='features', labelCol='total_amount', maxBins = 40)"]},{"cell_type":"markdown","id":"5be3fa57","metadata":{},"source":["***STEP 4: CREATING PIPELINE***"]},{"cell_type":"code","execution_count":12,"id":"ff7f2557","metadata":{},"outputs":[],"source":["from pyspark.ml import Pipeline"]},{"cell_type":"code","execution_count":13,"id":"d24ee451","metadata":{},"outputs":[],"source":["pipe = Pipeline(stages=[assembler, dt_regressor])"]},{"cell_type":"markdown","id":"f8bdd120","metadata":{},"source":["***STEP 5: TRAINING MODEL***"]},{"cell_type":"code","execution_count":14,"id":"8826f2fd","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["model = pipe.fit(trainDF)"]},{"cell_type":"markdown","id":"713c9665","metadata":{},"source":["***STEP 6: SHOWING PREDICTATED RESULTS***"]},{"cell_type":"code","execution_count":24,"id":"da5d41c7","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 118:==========================================>              (3 + 1) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------------+------------+\n","|passenger_count|pulocationid|dolocationid|        prediction|total_amount|\n","+---------------+------------+------------+------------------+------------+\n","|            1.0|        50.0|        48.0| 13.32710946479575|        9.68|\n","|            1.0|        51.0|        18.0|20.644553580295813|        22.3|\n","|            1.0|        61.0|        82.0| 13.32710946479575|        29.8|\n","|            1.0|        68.0|        14.0|20.644553580295813|        45.3|\n","|            1.0|        74.0|       130.0| 13.32710946479575|       43.56|\n","|            1.0|       132.0|       230.0| 49.33787412069614|        64.8|\n","|            1.0|       143.0|       100.0|13.537444086232135|       11.03|\n","|            1.0|       151.0|       161.0|12.202640378959797|        21.0|\n","|            1.0|       161.0|       232.0|12.202640378959797|       18.95|\n","|            1.0|       164.0|        87.0|13.537444086232135|       22.85|\n","+---------------+------------+------------+------------------+------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# Make predictions\n","pred = model.transform(testDF)\n","\n","# Show first 10 predictions along with features\n","pred.select('passenger_count', 'pulocationid', 'dolocationid', 'prediction', 'total_amount').show(10)"]},{"cell_type":"markdown","id":"c3c52c5a","metadata":{},"source":["***STEP 7: EVALUATING RESULTS***"]},{"cell_type":"code","execution_count":20,"id":"744ef838","metadata":{},"outputs":[],"source":["from pyspark.ml.evaluation import RegressionEvaluator"]},{"cell_type":"code","execution_count":26,"id":"642a41c1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 140:============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["RMSE: 138.45239637546695\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["evaluator = RegressionEvaluator(\n","    labelCol=\"total_amount\", \n","    predictionCol=\"prediction\", \n","    metricName=\"rmse\"\n",")\n","\n","rmse = evaluator.evaluate(pred)\n","print(f\"RMSE: {rmse}\")"]},{"cell_type":"markdown","id":"c9883b92","metadata":{},"source":["The RMSE is extremely high, showing that this model seems to not be accurate in predicting total amount. "]},{"cell_type":"code","execution_count":null,"id":"1e83051e","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}